name: Generate and Publish Dev.to Mirror Site

on:
  schedule:
    - cron: "40 13 * * 3"  # At 09:40 EDT every Wednesday; change to 14 for EST when applicable
  workflow_dispatch:
    inputs:
      force_full_regen:
        description: 'Force full regeneration (fetch all posts instead of incremental)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  deploy-mirror-site:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      DEVTO_USERNAME: ${{ vars.DEVTO_USERNAME }}
      DEVTO_API_KEY: ${{ secrets.DEVTO_API_KEY }}
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
      - name: Set up uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "latest"
          python-version: "3.12"
      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: ${{ runner.os }}-uv-${{ hashFiles('**/uv.lock') }}
          restore-keys: |
            ${{ runner.os }}-uv-
      - name: Install dependencies
        run: uv sync --locked --group dev && make install

      - name: Generate site
        if: env.DEVTO_USERNAME && env.DEVTO_API_KEY
        env:
          PAGES_REPO: ${{ github.repository }}
          FORCE_FULL_REGEN: ${{ github.event.inputs.force_full_regen || 'false' }}
        run: |
          echo "## ðŸ—ï¸ Site Generation Started" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ‘¤ Dev.to Username: \`${DEVTO_USERNAME}\`" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“¦ Target Repository: \`${{ github.repository }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”„ Full Regeneration: \`${FORCE_FULL_REGEN}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          uv run python scripts/generate_site.py

          username=$(echo $PAGES_REPO | cut -d'/' -f1)
          repo=$(echo $PAGES_REPO | cut -d'/' -f2)
          HOME="https://$username.github.io/$repo/"
          ROOT_HOME="https://$username.github.io/"

          # Prepare a temporary copy of the static assets directly from the
          # `assets/` directory (avoid relying on generator creating root copies).
          # This keeps the staging behavior simple: we always assemble TMPDIR from
          # authoritative sources. Fail fast if assets are missing.
          if [ ! -f assets/robots.txt ] || [ ! -f assets/llms.txt ]; then
            echo "Error: required assets (assets/robots.txt or assets/llms.txt) are missing" >&2
            exit 1
          fi

          # We'll perform substitutions on the copies placed into the project root
          # so later steps (and the site validator) can find them if needed.
          cp assets/robots.txt robots.txt
          cp assets/llms.txt llms.txt
          sed -i "s|{home}|$HOME|g" robots.txt
          sed -i "s|{root_home}|$ROOT_HOME|g" robots.txt
          sed -i "s|{home}|$HOME|g" llms.txt
          sed -i "s|{root_home}|$ROOT_HOME|g" llms.txt

          echo "- âœ… Site generation completed" >> $GITHUB_STEP_SUMMARY

      - name: Configure GitHub Pages
        if: env.DEVTO_USERNAME && env.DEVTO_API_KEY
        uses: actions/configure-pages@v5

      - name: Commit & push to gh-pages
        if: env.DEVTO_USERNAME && env.DEVTO_API_KEY
        run: |
          git config user.name "ci-bot"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          git commit -m "chore: auto-publish dev.to mirror" || echo "No changes"

          set -e
          TMPDIR="$(mktemp -d)"
          # Copy required and expected files into the temporary staging area. This
          # should fail immediately if any required file is missing (fail-fast).
          cp -R .nojekyll index.html comments.txt robots.txt sitemap.xml llms.txt posts posts_data.json scripts google6b80426bb396f31f.html "$TMPDIR/"
          if [ -d comments ]; then cp -R comments "$TMPDIR/"; fi
          if [ -f last_run.txt ]; then cp last_run.txt "$TMPDIR/"; fi

          git fetch --all --prune || true

          if git rev-parse --verify origin/gh-pages >/dev/null 2>&1; then
            git checkout gh-pages
            git reset --hard origin/gh-pages
          else
            git checkout --orphan gh-pages
            git rm -rf .
          fi

          cp -R "$TMPDIR"/posts ./
          cp -R "$TMPDIR"/comments ./
          cp "$TMPDIR"/robots.txt ./
          cp "$TMPDIR"/sitemap.xml ./
          cp "$TMPDIR"/llms.txt ./
          cp "$TMPDIR"/google6b80426bb396f31f.html ./
          if [ -f "$TMPDIR/last_run.txt" ]; then
            cp "$TMPDIR/last_run.txt" ./last_run.txt
          fi

          if [ -f "$TMPDIR/posts_data.json" ]; then
            cp "$TMPDIR/posts_data.json" posts_data_new.json
          fi

          if [ -d "$TMPDIR/scripts" ]; then
            cp -R "$TMPDIR/scripts" ./
          fi

          # We are now on the gh-pages branch. Run render_index_sitemap.py to regenerate
          # index.html and sitemap.xml using the posts_data.json we just copied.
          # This ensures the sitemap and index reflect the latest posts.
          if [ -f "scripts/render_index_sitemap.py" ]; then
            uv run python scripts/render_index_sitemap.py
          fi

          # Commit and push changes to gh-pages branch
          git add -A
          git commit -m "chore: deploy dev.to mirror" || echo "No changes to commit"
          git push origin gh-pages

          echo "- âœ… Pushed to gh-pages branch" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸš€ Deployment workflow will trigger automatically" >> $GITHUB_STEP_SUMMARY
