name: Dev.to Mirror (Static, Hourly)

on:
  schedule:
    - cron: "40 13 * * 3"  # At 09:40 EDT every Wednesday; change to 14 for EST when applicable
  workflow_dispatch: {}
  push:
    branches: [main]

permissions:
  contents: write
  pages: write

jobs:
  build:
    if: ${{ github.ref != 'refs/heads/gh-pages' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .

      - name: Generate site
        env:
          DEVTO_USERNAME: ${{ vars.DEVTO_USERNAME }}  # single variable only
          PAGES_REPO: ${{ github.repository }}        # "username/repo"
          # Use workflow_dispatch input to optionally force a full regeneration.
          FORCE_FULL_REGEN: ${{ github.event.inputs.full_regen || 'false' }}
        run: python scripts/generate_site.py

      - name: Prepare site for Pages deployment
        run: |
          set -euo pipefail
          OUT_DIR=out
          rm -rf "$OUT_DIR"
          mkdir -p "$OUT_DIR"
          # Copy site artifacts into a clean output directory
          cp -a .nojekyll index.html robots.txt sitemap.xml "$OUT_DIR/" || true
          if [ -d posts ]; then cp -a posts "$OUT_DIR/"; fi
          if [ -d comments ]; then cp -a comments "$OUT_DIR/"; fi
          if [ -f posts_data.json ]; then cp posts_data.json "$OUT_DIR/"; fi

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v1
        with:
          path: out

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v1
